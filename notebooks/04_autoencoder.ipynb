{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98290be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\ASUS\\OneDrive\\Desktop\\BTP PROJECT\\BTP_Implementation\\iiot-hybrid-detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"c:\\Users\\ASUS\\OneDrive\\Desktop\\BTP PROJECT\\BTP_Implementation\\iiot-hybrid-detection\")\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00966189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f369965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc268e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in h:\\ml krish naik udemy\\coding\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0106dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, roc_curve, auc\n",
    "\n",
    "from src.train_ae import train_autoencoder\n",
    "from src.constants import DATA_PATH, TARGET_COL, SEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562a271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0092\n",
      "Epoch 2/20, Loss: 0.0047\n",
      "Epoch 3/20, Loss: 0.0037\n",
      "Epoch 4/20, Loss: 0.0036\n",
      "Epoch 5/20, Loss: 0.0030\n",
      "Epoch 6/20, Loss: 0.0032\n",
      "Epoch 7/20, Loss: 0.0037\n",
      "Epoch 8/20, Loss: 0.0033\n",
      "Epoch 9/20, Loss: 0.0025\n",
      "Epoch 10/20, Loss: 0.0023\n",
      "Epoch 11/20, Loss: 0.0021\n",
      "Epoch 12/20, Loss: 0.0023\n",
      "Epoch 13/20, Loss: 0.0023\n",
      "Epoch 14/20, Loss: 0.0014\n",
      "Epoch 15/20, Loss: 0.0018\n",
      "Epoch 16/20, Loss: 0.0023\n",
      "Epoch 17/20, Loss: 0.0020\n",
      "Epoch 18/20, Loss: 0.0013\n",
      "Epoch 19/20, Loss: 0.0027\n",
      "Epoch 20/20, Loss: 0.0021\n",
      "✅ Autoencoder & preprocessor saved.\n"
     ]
    }
   ],
   "source": [
    "# Train autoencoder on Normal traffic only\n",
    "ae_model, preproc = train_autoencoder()\n",
    "\n",
    "# Save trained model + preprocessing\n",
    "os.makedirs(\"results/models\", exist_ok=True)\n",
    "joblib.dump(ae_model, \"results/models/autoencoder.pkl\")\n",
    "joblib.dump(preproc, \"results/models/ae_preprocessor.pkl\")\n",
    "print(\"✅ Autoencoder & preprocessor saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a274b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preproc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_PATH)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_all \u001b[38;5;241m=\u001b[39m \u001b[43mpreproc\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[TARGET_COL]))\n\u001b[0;32m      6\u001b[0m y_true \u001b[38;5;241m=\u001b[39m (df[TARGET_COL] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)   \u001b[38;5;66;03m# anomaly = 1, normal = 0\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Reconstruction\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preproc' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Preprocess\n",
    "X_all = preproc.transform(df.drop(columns=[TARGET_COL]))\n",
    "y_true = (df[TARGET_COL] != \"normal\").astype(int)   # anomaly = 1, normal = 0\n",
    "\n",
    "# Reconstruction\n",
    "recon = ae_model(torch.tensor(X_all).float()).detach().numpy()\n",
    "errors = ((X_all - recon) ** 2).mean(axis=1)\n",
    "\n",
    "# Threshold (mean + 3*std)\n",
    "threshold = errors.mean() + 3*errors.std()\n",
    "y_pred = (errors > threshold).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc = roc_auc_score(y_true, errors)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n",
    "print(f\"ROC-AUC={roc:.3f} | Precision={prec:.3f} | Recall={rec:.3f} | F1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce107561",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results/reports\", exist_ok=True)\n",
    "report = {\n",
    "    \"roc_auc\": float(roc),\n",
    "    \"precision\": float(prec),\n",
    "    \"recall\": float(rec),\n",
    "    \"f1\": float(f1),\n",
    "    \"threshold\": float(threshold)\n",
    "}\n",
    "with open(\"results/reports/autoencoder_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "\n",
    "print(\"✅ Report saved to results/reports/autoencoder_report.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results/plots\", exist_ok=True)\n",
    "\n",
    "# Error histogram\n",
    "plt.hist(errors[y_true==0], bins=50, alpha=0.5, label=\"Normal\")\n",
    "plt.hist(errors[y_true==1], bins=50, alpha=0.5, label=\"Attack\")\n",
    "plt.legend(); plt.title(\"Reconstruction Errors\")\n",
    "plt.xlabel(\"Error\"); plt.ylabel(\"Count\")\n",
    "plt.savefig(\"results/plots/ae_error_hist.png\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, errors)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc(fpr,tpr):.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\")\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(\"Autoencoder ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/plots/ae_roc.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546fba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plots saved in results/plots/ as test_model_accuracy.png and test_model_loss.png\n"
     ]
    }
   ],
   "source": [
    "from src.plot_utils import plot_training_curves\n",
    "\n",
    "# Example dummy data to test plotting\n",
    "history = {\n",
    "    \"train_acc\": [0.81, 0.85, 0.89, 0.91, 0.93, 0.94, 0.945],\n",
    "    \"val_acc\":   [0.80, 0.83, 0.87, 0.90, 0.91, 0.935, 0.940],\n",
    "    \"train_loss\": [0.48, 0.35, 0.28, 0.23, 0.19, 0.16, 0.14],\n",
    "    \"val_loss\":   [0.50, 0.38, 0.32, 0.27, 0.23, 0.20, 0.18]\n",
    "}\n",
    "\n",
    "plot_training_curves(history, model_name=\"test_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d036d7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/50]  train_loss=0.011365  val_loss=0.015208\n",
      "[saved best] epoch 1 val_loss=0.015208\n",
      "Epoch [2/50]  train_loss=0.004333  val_loss=0.013682\n",
      "[saved best] epoch 2 val_loss=0.013682\n",
      "Epoch [3/50]  train_loss=0.003685  val_loss=0.016441\n",
      "Epoch [4/50]  train_loss=0.003533  val_loss=0.010751\n",
      "[saved best] epoch 4 val_loss=0.010751\n",
      "Epoch [5/50]  train_loss=0.003077  val_loss=0.009860\n",
      "[saved best] epoch 5 val_loss=0.009860\n",
      "Epoch [6/50]  train_loss=0.001848  val_loss=0.010985\n",
      "Epoch [7/50]  train_loss=0.002748  val_loss=0.020543\n",
      "Epoch [8/50]  train_loss=0.003247  val_loss=0.012216\n",
      "Epoch [9/50]  train_loss=0.003019  val_loss=0.010934\n",
      "Epoch [10/50]  train_loss=0.002486  val_loss=0.009435\n",
      "[saved best] epoch 10 val_loss=0.009435\n",
      "Epoch [11/50]  train_loss=0.001906  val_loss=0.008000\n",
      "[saved best] epoch 11 val_loss=0.008000\n",
      "Epoch [12/50]  train_loss=0.001558  val_loss=0.009723\n",
      "Epoch [13/50]  train_loss=0.001907  val_loss=0.015032\n",
      "Epoch [14/50]  train_loss=0.003590  val_loss=0.010856\n",
      "Epoch [15/50]  train_loss=0.002351  val_loss=0.010247\n",
      "Epoch [16/50]  train_loss=0.002101  val_loss=0.009544\n",
      "Epoch [17/50]  train_loss=0.001832  val_loss=0.008634\n",
      "Epoch [18/50]  train_loss=0.001292  val_loss=0.008004\n",
      "Epoch [19/50]  train_loss=0.001341  val_loss=0.010316\n",
      "Epoch [20/50]  train_loss=0.002258  val_loss=0.010165\n",
      "Epoch [21/50]  train_loss=0.001936  val_loss=0.009235\n",
      "Epoch [22/50]  train_loss=0.002252  val_loss=0.010561\n",
      "Epoch [23/50]  train_loss=0.002402  val_loss=0.008952\n",
      "Epoch [24/50]  train_loss=0.001531  val_loss=0.008024\n",
      "Epoch [25/50]  train_loss=0.001212  val_loss=0.007565\n",
      "[saved best] epoch 25 val_loss=0.007565\n",
      "Epoch [26/50]  train_loss=0.001189  val_loss=0.007149\n",
      "[saved best] epoch 26 val_loss=0.007149\n",
      "Epoch [27/50]  train_loss=0.000939  val_loss=0.008235\n",
      "Epoch [28/50]  train_loss=0.001389  val_loss=0.008253\n",
      "Epoch [29/50]  train_loss=0.001507  val_loss=0.007119\n",
      "[saved best] epoch 29 val_loss=0.007119\n",
      "Epoch [30/50]  train_loss=0.000959  val_loss=0.006497\n",
      "[saved best] epoch 30 val_loss=0.006497\n",
      "Epoch [31/50]  train_loss=0.000719  val_loss=0.006357\n",
      "[saved best] epoch 31 val_loss=0.006357\n",
      "Epoch [32/50]  train_loss=0.000837  val_loss=0.007044\n",
      "Epoch [33/50]  train_loss=0.001136  val_loss=0.008656\n",
      "Epoch [34/50]  train_loss=0.001224  val_loss=0.006620\n",
      "Epoch [35/50]  train_loss=0.001059  val_loss=0.006111\n",
      "[saved best] epoch 35 val_loss=0.006111\n",
      "Epoch [36/50]  train_loss=0.000702  val_loss=0.006141\n",
      "Epoch [37/50]  train_loss=0.000869  val_loss=0.005835\n",
      "[saved best] epoch 37 val_loss=0.005835\n",
      "Epoch [38/50]  train_loss=0.000694  val_loss=0.005801\n",
      "[saved best] epoch 38 val_loss=0.005801\n",
      "Epoch [39/50]  train_loss=0.000872  val_loss=0.006262\n",
      "Epoch [40/50]  train_loss=0.000858  val_loss=0.005515\n",
      "[saved best] epoch 40 val_loss=0.005515\n",
      "Epoch [41/50]  train_loss=0.000715  val_loss=0.005799\n",
      "Epoch [42/50]  train_loss=0.000729  val_loss=0.005701\n",
      "Epoch [43/50]  train_loss=0.000694  val_loss=0.005874\n",
      "Epoch [44/50]  train_loss=0.000843  val_loss=0.005448\n",
      "[saved best] epoch 44 val_loss=0.005448\n",
      "Epoch [45/50]  train_loss=0.000609  val_loss=0.005494\n",
      "Epoch [46/50]  train_loss=0.001111  val_loss=0.005810\n",
      "Epoch [47/50]  train_loss=0.000563  val_loss=0.005681\n",
      "Epoch [48/50]  train_loss=0.000704  val_loss=0.005023\n",
      "[saved best] epoch 48 val_loss=0.005023\n",
      "Epoch [49/50]  train_loss=0.000516  val_loss=0.005263\n",
      "Epoch [50/50]  train_loss=0.000737  val_loss=0.005210\n",
      "Training complete. Best model saved to results/models/autoencoder_state.pt\n"
     ]
    }
   ],
   "source": [
    "# notebook cell\n",
    "from src.train_ae import train_autoencoder\n",
    "import torch, os\n",
    "\n",
    "# choose device (optional override)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# train for 50 epochs\n",
    "ae_model, preproc, history = train_autoencoder(\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    checkpoint_dir=\"results/models\",\n",
    "    checkpoint_name=\"autoencoder_checkpoint.pth\",\n",
    "    save_best_as=\"results/models/autoencoder_state.pt\",\n",
    "    resume_from=None,  # or \"results/models/autoencoder_checkpoint.pth\" to resume\n",
    "    early_stopping_patience=None  # or e.g. 8\n",
    ")\n",
    "\n",
    "print(\"Training complete. Best model saved to results/models/autoencoder_state.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3190ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plots saved in results/plots/ as autoencoder_50epochs_accuracy.png and autoencoder_50epochs_loss.png\n"
     ]
    }
   ],
   "source": [
    "from src.plot_utils import plot_training_curves\n",
    "\n",
    "# history is dict with lists: train_acc, val_acc, train_loss, val_loss\n",
    "plot_training_curves(history, model_name=\"autoencoder_50epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df76a6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.05 GiB for an array with shape (211043, 1304) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     21\u001b[0m     recon \u001b[38;5;241m=\u001b[39m ae(torch\u001b[38;5;241m.\u001b[39mtensor(X)\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 22\u001b[0m errors \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m)\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# true labels: 0 normal, 1 attack\u001b[39;00m\n\u001b[0;32m     25\u001b[0m y_true \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39m(df[TARGET_COL]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.05 GiB for an array with shape (211043, 1304) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, torch, joblib, os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from src.constants import DATA_PATH, TARGET_COL\n",
    "\n",
    "# load df and preproc + model\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[TARGET_COL] = df[TARGET_COL].astype(str).str.lower()\n",
    "\n",
    "preproc = joblib.load(\"results/models/ae_preprocessor.joblib\")\n",
    "model = torch.load(\"results/models/autoencoder_state.pt\", map_location=\"cpu\")\n",
    "# if the model object class is defined in src.train_ae.Autoencoder, instantiate and load:\n",
    "from src.train_ae import Autoencoder\n",
    "input_dim = preproc.transform(df.drop(columns=[TARGET_COL]).iloc[:1]).shape[1]\n",
    "ae = Autoencoder(input_dim=input_dim)\n",
    "ae.load_state_dict(torch.load(\"results/models/autoencoder_state.pt\", map_location=\"cpu\"))\n",
    "ae.eval()\n",
    "\n",
    "# transform everything\n",
    "X = preproc.transform(df.drop(columns=[TARGET_COL]))\n",
    "with torch.no_grad():\n",
    "    recon = ae(torch.tensor(X).float()).numpy()\n",
    "errors = ((X - recon) ** 2).mean(axis=1)\n",
    "\n",
    "# true labels: 0 normal, 1 attack\n",
    "y_true = (~(df[TARGET_COL].str.lower() == \"normal\")).astype(int).values\n",
    "auc = roc_auc_score(y_true, errors)\n",
    "print(\"AE ROC-AUC:\", auc)\n",
    "\n",
    "# save errors and results\n",
    "np.save(\"results/reports/ae_errors.npy\", errors)\n",
    "pd.DataFrame({\"true\":y_true, \"error\":errors}).to_csv(\"results/reports/ae_errors_table.csv\", index=False)\n",
    "\n",
    "# save ROC plot and histogram (use earlier eval code or write a quick plot)\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, _ = roc_curve(y_true, errors)\n",
    "plt.figure(); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--'); plt.title(f\"AE ROC (AUC={auc:.3f})\"); plt.savefig(\"results/reports/ae_roc.png\", dpi=300); plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(errors[y_true==0], bins=80, alpha=0.6, label=\"normal\")\n",
    "plt.hist(errors[y_true==1], bins=80, alpha=0.6, label=\"attack\")\n",
    "plt.legend(); plt.title(\"AE Reconstruction Error\"); plt.savefig(\"results/reports/ae_error_hist.png\", dpi=300); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec910183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Processing 211043 samples in batches of 5000...\n",
      "Processed 5000/211043 samples...\n",
      "Processed 10000/211043 samples...\n",
      "Processed 15000/211043 samples...\n",
      "Processed 20000/211043 samples...\n",
      "Processed 25000/211043 samples...\n",
      "Processed 30000/211043 samples...\n",
      "Processed 35000/211043 samples...\n",
      "Processed 40000/211043 samples...\n",
      "Processed 45000/211043 samples...\n",
      "Processed 50000/211043 samples...\n",
      "Processed 55000/211043 samples...\n",
      "Processed 60000/211043 samples...\n",
      "Processed 65000/211043 samples...\n",
      "Processed 70000/211043 samples...\n",
      "Processed 75000/211043 samples...\n",
      "Processed 80000/211043 samples...\n",
      "Processed 85000/211043 samples...\n",
      "Processed 90000/211043 samples...\n",
      "Processed 95000/211043 samples...\n",
      "Processed 100000/211043 samples...\n",
      "Processed 105000/211043 samples...\n",
      "Processed 110000/211043 samples...\n",
      "Processed 115000/211043 samples...\n",
      "Processed 120000/211043 samples...\n",
      "Processed 125000/211043 samples...\n",
      "Processed 130000/211043 samples...\n",
      "Processed 135000/211043 samples...\n",
      "Processed 140000/211043 samples...\n",
      "Processed 145000/211043 samples...\n",
      "Processed 150000/211043 samples...\n",
      "Processed 155000/211043 samples...\n",
      "Processed 160000/211043 samples...\n",
      "Processed 165000/211043 samples...\n",
      "Processed 170000/211043 samples...\n",
      "Processed 175000/211043 samples...\n",
      "Processed 180000/211043 samples...\n",
      "Processed 185000/211043 samples...\n",
      "Processed 190000/211043 samples...\n",
      "Processed 195000/211043 samples...\n",
      "Processed 200000/211043 samples...\n",
      "Processed 205000/211043 samples...\n",
      "Processed 210000/211043 samples...\n",
      "Processed 211043/211043 samples...\n",
      "✅ AE ROC-AUC: 0.9863049502306838\n",
      "Saved AE error table and numpy array.\n",
      "Saved ROC curve.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from src.constants import DATA_PATH, TARGET_COL\n",
    "from src.train_ae import Autoencoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======================================\n",
    "# 1. Load data\n",
    "# ======================================\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[TARGET_COL] = df[TARGET_COL].astype(str).str.lower()\n",
    "\n",
    "# Load preprocessor and model\n",
    "preproc = joblib.load(\"results/models/ae_preprocessor.joblib\")\n",
    "\n",
    "input_dim = preproc.transform(df.drop(columns=[TARGET_COL]).iloc[:1]).shape[1]\n",
    "ae = Autoencoder(input_dim=input_dim)\n",
    "ae.load_state_dict(torch.load(\"results/models/autoencoder_state.pt\", map_location=\"cpu\"))\n",
    "ae.eval()\n",
    "\n",
    "# Ensure results folder exists\n",
    "os.makedirs(\"results/reports\", exist_ok=True)\n",
    "\n",
    "# ======================================\n",
    "# 2. Batch processing\n",
    "# ======================================\n",
    "BATCH_SIZE = 5000  # Adjust based on memory\n",
    "n_samples = df.shape[0]\n",
    "errors = []\n",
    "\n",
    "print(f\"Processing {n_samples} samples in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "# Loop through batches\n",
    "for start in range(0, n_samples, BATCH_SIZE):\n",
    "    end = min(start + BATCH_SIZE, n_samples)\n",
    "    \n",
    "    # --- Use DataFrame slice instead of NumPy ---\n",
    "    batch_df = df.iloc[start:end].drop(columns=[TARGET_COL])\n",
    "    \n",
    "    # Transform using the preprocessor\n",
    "    X_batch = preproc.transform(batch_df)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    X_tensor = torch.tensor(X_batch, dtype=torch.float32)\n",
    "    \n",
    "    # Autoencoder reconstruction\n",
    "    with torch.no_grad():\n",
    "        recon = ae(X_tensor).numpy()\n",
    "    \n",
    "    # Compute reconstruction error for batch\n",
    "    batch_errors = np.mean((X_batch - recon) ** 2, axis=1)\n",
    "    errors.extend(batch_errors)\n",
    "\n",
    "    print(f\"Processed {end}/{n_samples} samples...\")\n",
    "\n",
    "errors = np.array(errors)\n",
    "\n",
    "# ======================================\n",
    "# 3. Evaluate\n",
    "# ======================================\n",
    "# true labels: 0 = normal, 1 = attack\n",
    "y_true = (~(df[TARGET_COL].str.lower() == \"normal\")).astype(int).values\n",
    "auc = roc_auc_score(y_true, errors)\n",
    "print(\"✅ AE ROC-AUC:\", auc)\n",
    "\n",
    "# ======================================\n",
    "# 4. Save results\n",
    "# ======================================\n",
    "np.save(\"results/reports/ae_errors.npy\", errors)\n",
    "pd.DataFrame({\"true\": y_true, \"error\": errors}).to_csv(\"results/reports/ae_errors_table.csv\", index=False)\n",
    "print(\"Saved AE error table and numpy array.\")\n",
    "\n",
    "# ======================================\n",
    "# 5. Plot ROC & histogram\n",
    "# ======================================\n",
    "# --- ROC Curve ---\n",
    "fpr, tpr, _ = roc_curve(y_true, errors)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Autoencoder ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/reports/ae_roc.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved ROC curve.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeaf4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ROC Curve ---\n",
    "fpr, tpr, _ = roc_curve(y_true, errors)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Autoencoder ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"results/reports/ae_roc.png\", dpi=300)\n",
    "plt.close()   # ✅ fixed here\n",
    "\n",
    "# --- Histogram ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(errors[y_true == 0], bins=80, alpha=0.6, label=\"Normal\")\n",
    "plt.hist(errors[y_true == 1], bins=80, alpha=0.6, label=\"Attack\")\n",
    "plt.legend()\n",
    "plt.title(\"AE Reconstruction Error Distribution\")\n",
    "plt.savefig(\"results/reports/ae_error_hist.png\", dpi=300)\n",
    "plt.close()   # ✅ fixed here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941ba35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
